# main_script.py
import json
import re
import pdfplumber
from docx import Document
from docx.table import Table, _Cell
from docx.text.paragraph import Paragraph
from docx.oxml.text.paragraph import CT_P
from docx.oxml.table import CT_Tbl
from docx.oxml import OxmlElement
from docx.oxml.ns import qn

# --- ë‹¤ë¥¸ íŒŒì¼ì—ì„œ í•¨ìˆ˜ ì„í¬íŠ¸ ---
from report_table_parser import parse_table
from report_math_parser import parse_omml_to_latex_like
# ---------------------------------

# --- íŒŒì¼ ê²½ë¡œ ì„¤ì • ---
DOCX_PATH = "C://GSCert//myproject//GS-B-25-0094 ì‹œí—˜ì„±ì ì„œ v1.0.docx"
PDF_PATH = "C://GSCert//myproject//GS-B-25-0094 ì‹œí—˜ì„±ì ì„œ v1.0.pdf"
# ---------------------

def normalize_text(text: str):
    """í…ìŠ¤íŠ¸ì˜ ëª¨ë“  ì¢…ë¥˜ ê³µë°±(ìœ ë‹ˆì½”ë“œ í¬í•¨)ì„ ë‹¨ì¼ ìŠ¤í˜ì´ìŠ¤ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    if not text: return ""
    return re.sub(r'\s+', ' ', text).strip()

# --- 1. ë¼ë²¨ ì‹ë³„ í•¨ìˆ˜ (ë™ì¼) ---
RE_VER_STRING = re.compile(r'^\s*v\d+\.\d+')
RE_NUM_LABEL = re.compile(r'^\s*(\d+(\.\d+)*)[\.\s]\s*(.*)')
RE_TAG_LABEL = re.compile(r'^\s*<\s*([^>]+?)\s*>\s*(.*)')

def get_label_info(text: str):
    clean_text = text.strip()
    if not clean_text or RE_VER_STRING.match(clean_text): return None
    if clean_text.startswith("Â·"): return None

    match = None; depth = 1; label_prefix = ""; full_label_text = ""
    match_num = RE_NUM_LABEL.match(clean_text)
    if match_num:
        label_prefix = match_num.group(1).strip(); full_label_text = match_num.group(3).strip()
        depth = label_prefix.count('.') + 1
        if not full_label_text and clean_text.endswith('.'):
             if clean_text == label_prefix + '.': label_prefix += "."
        match = match_num
    match_tag = RE_TAG_LABEL.match(clean_text)
    if match_tag:
        label_prefix = f"<{match_tag.group(1).strip()}>"; full_label_text = match_tag.group(2).strip()
        depth = 1; match = match_tag
    if not match: return None

    final_label = ""; final_rest = ""
    if ':' in full_label_text:
        parts = full_label_text.split(':', 1)
        final_label = f"{label_prefix} {parts[0].strip()}".strip(); final_rest = parts[1].strip()
    else:
        final_label = f"{label_prefix} {full_label_text}".strip(); final_rest = ""
    if final_label.endswith('.'):
         original_suffix = clean_text.replace(label_prefix, '').strip()
         if original_suffix == '.': final_label = label_prefix
    if not full_label_text.strip() and label_prefix:
        if label_prefix.endswith('.'): final_label = label_prefix
    if re.match(r'^\d+\.$', final_label): return None
    return final_label, final_rest, depth

# --- 2. PDF ë¶„ì„ í•¨ìˆ˜ (7% ê²½ê³„ ìˆ˜ì •) ---
def analyze_pdf(pdf_path: str):
    """
    [7% ê²½ê³„ ìˆ˜ì •] PDFë¥¼ ë¶„ì„í•˜ê³  extract_wordsë¡œ ì²« ì¤„ ì•µì»¤ë¥¼ ì¶”ì¶œ/ì •ê·œí™”í•©ë‹ˆë‹¤.
    """
    print(f"--- 1. PDF ë¶„ì„ ì‹œì‘: {pdf_path} ---")
    pdf_data = {}; total_pages = 0
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages); print(f"ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")
        for i, page in enumerate(pdf.pages):
            page_num = page.page_number; height = page.height
            header_boundary = height * 0.07 # 7% ìˆ˜ì •
            footer_boundary = height * 0.93 # 7% ìˆ˜ì •
            header_lines = []; footer_lines = []

            words = page.extract_words(keep_blank_chars=True, y_tolerance=3, x_tolerance=1)
            content_words = [w for w in words if header_boundary <= w['top'] and w['bottom'] <= footer_boundary]
            anchor_text = None
            if content_words:
                first_word = min(content_words, key=lambda w: w['top']); first_line_top = first_word['top']
                first_line_words = sorted([w for w in content_words if abs(w['top'] - first_line_top) < 3], key=lambda w: w['x0'])
                anchor_raw_text = "".join(w['text'] for w in first_line_words)
                anchor_text = normalize_text(anchor_raw_text)

            all_lines = page.extract_text_lines(return_chars=False)
            if all_lines:
                 for line in all_lines:
                     text = line['text'];
                     if not text.strip(): continue
                     page_match = re.search(r'í˜ì´ì§€\s*:\s*\(\s*(\d+)\s*\)\s*(?:/\s*\(ì´?\s*(\d+)\s*\))?', text)
                     if page_match and line['bottom'] > footer_boundary:
                          current_pg=page_match.group(1); total_pg_num=page_match.group(2) or total_pages
                          footer_lines.append(f"í˜ì´ì§€: ({current_pg})/({total_pg_num})")
                     elif line['top'] < header_boundary: header_lines.append(text.strip())
                     elif line['bottom'] > footer_boundary:
                         clean_line = text.strip()
                         if "í˜ì´ì§€" not in clean_line and clean_line not in footer_lines: footer_lines.append(clean_line)

            footer_lines = sorted(list(set(footer_lines)))
            pdf_data[page_num] = {"header": sorted(list(set(header_lines))), "footer": footer_lines, "anchor": anchor_text}
            if i < 7 or i > total_pages - 3: print(f"  [Page {page_num}] ì•µì»¤: '{anchor_text}' / í‘¸í„° ìƒ˜í”Œ: {footer_lines[:2]}")
    print("--- 1. PDF ë¶„ì„ ì™„ë£Œ ---")
    return total_pages, pdf_data

# --- 3. DOCX 1ì°¨ íŒŒì‹± (math_parser, table_parser í˜¸ì¶œ) ---
def parse_docx_flat(docx_path: str, pdf_page_data: dict):
    """
    [ìˆ˜ì •] math_parserì™€ table_parser í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    print(f"--- 2. DOCX 1ì°¨ íŒŒì‹± ì‹œì‘: {docx_path} ---")
    anchors = {};
    for p_num, data in pdf_page_data.items():
        anchor = data.get('anchor');
        if anchor and anchor not in anchors: anchors[anchor] = p_num

    doc = Document(docx_path)
    page_flat_content = {p_num: [] for p_num in pdf_page_data.keys()}
    current_page_num = 1; is_page_1_table_processed = False

    for element in doc.element.body:
        block = None; is_anchor_found = False; current_element_anchor_text = None

        if isinstance(element, CT_P):
            para = Paragraph(element, doc)
            current_element_anchor_text = normalize_text(para.text)

            if current_element_anchor_text and current_element_anchor_text in anchors:
                new_page_num = anchors[current_element_anchor_text]
                if new_page_num != current_page_num:
                    print(f"  [í˜ì´ì§€ ì „í™˜] P: '{current_element_anchor_text}' -> Page {new_page_num}")
                    current_page_num = new_page_num
                is_anchor_found = True

            # --- ìˆ˜ì‹ ì²˜ë¦¬ ---
            # ë‹¨ë½ XML ë‚´ë¶€ì— <m:oMathPara> ë˜ëŠ” <m:oMath> íƒœê·¸ê°€ ìˆëŠ”ì§€ í™•ì¸
            omml_tags = element.xpath('.//m:oMathPara | .//m:oMath', namespaces={'m': ns['m']})
            if omml_tags:
                 print(f"  [ìˆ˜ì‹ ë°œê²¬] Page {current_page_num}, ë‚´ìš©: {para.text[:30]}...")
                 # ì²« ë²ˆì§¸ ìˆ˜ì‹ íƒœê·¸ì˜ XML ë¬¸ìì—´ ì¶”ì¶œ
                 omml_xml_string = ET.tostring(omml_tags[0], encoding='unicode')
                 # math_parser í˜¸ì¶œ
                 math_text = parse_omml_to_latex_like(omml_xml_string)
                 block = {"type": "sen", "sen": math_text}
                 # TODO: ìˆ˜ì‹ ì•ë’¤ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•„ìš” ì‹œ ì¶”ê°€ ë¡œì§
            elif para.text.strip(): # ìˆ˜ì‹ì´ ì•„ë‹ˆê³  ë¹ˆ ë‹¨ë½ë„ ì•„ë‹ˆë©´ ê¸°ì¡´ ë¡œì§
                label_info = get_label_info(para.text.strip())
                if label_info:
                    label, rest, depth = label_info
                    block = {"type": "label", "label": label, "content": [], "depth": depth}
                    if rest: block["content"].append({"sen": rest})
                else:
                    block = {"type": "sen", "sen": para.text.strip()}

        elif isinstance(element, CT_Tbl):
            table = Table(element, doc)
            if table.rows:
                first_row_cells = table.rows[0].cells
                for cell in first_row_cells:
                    cell_text_normalized = normalize_text(cell.text)
                    if cell_text_normalized and cell_text_normalized in anchors:
                        new_page_num = anchors[cell_text_normalized]
                        if new_page_num != current_page_num:
                            print(f"  [í˜ì´ì§€ ì „í™˜] T: '{cell_text_normalized}' -> Page {new_page_num}")
                            current_page_num = new_page_num
                        is_anchor_found = True; current_element_anchor_text = cell_text_normalized
                        break

            if table.rows:
               # --- table_parser í˜¸ì¶œ ---
               block = parse_table(table)
               block["type"] = "table"

        if block: page_flat_content[current_page_num].append(block)

        # --- 1í˜ì´ì§€ íŠ¹ìˆ˜ ì²˜ë¦¬ (ë™ì¼) ---
        if (current_page_num == 1 and block and block.get("type") == "table" and
            current_element_anchor_text == "ì‹œí—˜ì„±ì ì„œ" and not is_page_1_table_processed):
            print("  [Page 1] í…Œì´ë¸” ë‚´ë¶€ ë¼ë²¨/sen ì¶”ì¶œ ì¤‘...")
            is_page_1_table_processed = True
            try:
                tbl_element = element; tr = tbl_element.tr_lst[2]; tc = tr.tc_lst[1]
                page_1_stack = []
                for p in tc.xpath('.//w:p', namespaces=qn.nsmap): # Use qn.nsmap
                    para = Paragraph(p, table); para_text = para.text.strip()
                    if not para_text: continue
                    label_info = get_label_info(para_text)
                    if label_info:
                        label, rest, depth = label_info
                        new_block = {"type": "label", "label": label, "content": [], "depth": depth}
                        if rest: new_block["content"].append({"sen": rest})
                        page_flat_content[current_page_num].append(new_block)
                        page_1_stack = [(new_block, depth)]
                    elif para_text.startswith("Â·") and page_1_stack:
                        last_label_block_ref, _ = page_1_stack[-1]
                        if "content" not in last_label_block_ref: last_label_block_ref["content"] = []
                        last_label_block_ref["content"].append({"sen": para_text})
            except (IndexError, AttributeError) as e:
                print(f"  [ê²½ê³ ] 1í˜ì´ì§€ í…Œì´ë¸” êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}.")
                pass
    print("--- 2. DOCX 1ì°¨ íŒŒì‹± ì™„ë£Œ ---")
    return page_flat_content


# --- 4. 2ì°¨ íŒŒì‹± (ì¤‘ì²© êµ¬ì¡° ìƒì„±) í•¨ìˆ˜ (ë™ì¼) ---
def build_nested_content(flat_blocks: list):
    nested_content = []; stack = []
    for block in flat_blocks:
        block_type = block.get("type")
        if "type" in block: block.pop("type")
        elif "sen" in block: block_type = "sen"
        elif "table" in block: block_type = "table"
        else: continue
        if block_type == "label":
            depth = block.pop("depth", 1)
            while stack and stack[-1][1] >= depth: stack.pop()
            if not stack: nested_content.append(block)
            else:
                parent_label_block, _ = stack[-1]
                if "content" not in parent_label_block: parent_label_block["content"] = []
                parent_label_block["content"].append(block)
            stack.append((block, depth))
        elif block_type in ["sen", "table"]:
             current_block = block #if block_type else {"sen": block["sen"]}
             if not stack: nested_content.append(current_block)
             else:
                 parent_label_block, _ = stack[-1]
                 if "content" not in parent_label_block: parent_label_block["content"] = []
                 parent_label_block["content"].append(current_block)
    return nested_content

# --- 5. ì»¤ìŠ¤í…€ JSON ì €ì¥ í•¨ìˆ˜ (ë™ì¼) ---
def save_as_custom_json(data, filename: str):
    print(f"--- 4. ì»¤ìŠ¤í…€ JSON í¬ë§·íŒ… ë° ì €ì¥ ì‹œì‘: {filename} ---")
    try:
        pretty_json_str = json.dumps(data, indent=2, ensure_ascii=False)
    except TypeError as e:
        print(f"  [ì˜¤ë¥˜] JSON ì§ë ¬í™” ì‹¤íŒ¨: {e}");
        with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"  [ê²½ê³ ] ê¸°ë³¸ í¬ë§·ìœ¼ë¡œ ì €ì¥ë¨."); return

    table_block_regex = re.compile(r'"table":\s*(\[.*?\])', re.DOTALL)
    def compress_table_match(match):
        table_str = match.group(1)
        try:
            table_list = json.loads(table_str)
            compressed_str = json.dumps(table_list, ensure_ascii=False, separators=(',', ':')) # ê³µë°± ìµœì†Œí™”
            return f'"table": {compressed_str}'
        except json.JSONDecodeError as e:
            print(f"  [ê²½ê³ ] í…Œì´ë¸” JSON ì••ì¶• ì‹¤íŒ¨ (íŒŒì‹± ì˜¤ë¥˜): {e} - {table_str[:100]}...")
            return match.group(0)
    final_json_str = table_block_regex.sub(compress_table_match, pretty_json_str)
    with open(filename, 'w', encoding='utf-8') as f: f.write(final_json_str)


# --- 6. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë™ì¼) ---
def main():
    try: total_pages, pdf_page_data = analyze_pdf(PDF_PATH)
    except Exception as e: print(f"PDF ë¶„ì„ ì˜¤ë¥˜: {e}"); return
    try: all_pages_flat_content = parse_docx_flat(DOCX_PATH, pdf_page_data)
    except Exception as e: import traceback; print(f"DOCX íŒŒì‹± ì˜¤ë¥˜: {e}"); traceback.print_exc(); return

    print("--- 3. ì¤‘ì²© êµ¬ì¡° ìƒì„± ì‹œì‘ ---"); final_pages_list = []
    for page_num in sorted(pdf_page_data.keys()):
        flat_blocks = all_pages_flat_content.get(page_num, [])
        if page_num == 3: # ëª©ì°¨
            content = []
            for block in flat_blocks:
                 block_type = block.get("type")
                 if block_type == "label": content.append({"sen": block["label"]})
                 elif block_type == "sen": content.append({"sen": block["sen"]})
        else: content = build_nested_content(flat_blocks)
        page_obj = {"page": page_num, "header": pdf_page_data.get(page_num, {}).get("header", []),
                    "footer": pdf_page_data.get(page_num, {}).get("footer", []), "content": content}
        final_pages_list.append(page_obj)
    print("--- 3. ì¤‘ì²© êµ¬ì¡° ìƒì„± ì™„ë£Œ ---")

    final_json = {"v": "0.4", "total_pages": total_pages, "pages": final_pages_list}
    output_filename = "output.json"
    try: save_as_custom_json(final_json, output_filename); print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ! ê²°ê³¼ê°€ {output_filename} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e: print(f"ìµœì¢… JSON ì €ì¥ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
